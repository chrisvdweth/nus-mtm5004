{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e34a97dc-f1d7-40dd-b859-e61de6176579",
   "metadata": {},
   "source": [
    "<img src=\"data/images/div/lecture-notebook-header.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eea91f-03c9-49c3-8265-eb9333f9c1ad",
   "metadata": {},
   "source": [
    "# Image Classification with CNN (Convolutional Neural Network)\n",
    "\n",
    "Image classification using neural networks involves training a model to identify and categorize images into predefined classes or categories. The process involves feeding a neural network with labeled images (input) and allowing the network to learn patterns and features inherent to different classes. The network then makes predictions about the class to which new, unseen images belong.\n",
    "\n",
    "The steps generally involve:\n",
    "\n",
    "* **Data Preparation:** Collecting and preprocessing a dataset of labeled images. This involves splitting the dataset into training, validation, and test sets.\n",
    "\n",
    "* **Model Building:** Constructing a neural network architecture suitable for image classification. Convolutional Neural Networks (CNNs) are commonly used due to their ability to extract features hierarchically from images.\n",
    "\n",
    "* **Training:** The model is trained using the training dataset by adjusting its parameters to minimize the difference between predicted and actual labels. This is typically done through forward and backward propagation, updating weights using optimization algorithms like stochastic gradient descent.\n",
    "\n",
    "* **Validation:** Validating the trained model's performance using the validation dataset to fine-tune hyperparameters and prevent overfitting.\n",
    "\n",
    "* **Testing:** Assessing the model's accuracy and performance on unseen data (test dataset) to evaluate its ability to correctly classify new images.\n",
    "\n",
    "Applications of image classification using neural networks are extensive and impactful:\n",
    "\n",
    "* **Medical Imaging:** Diagnosing diseases from X-rays, MRIs, and CT scans.\n",
    "\n",
    "* **Object Recognition:** Autonomous vehicles, robotics, and surveillance systems use image classification to identify objects.\n",
    "\n",
    "* **Quality Control:** Sorting and inspecting products in manufacturing based on defects or characteristics.\n",
    "\n",
    "* **Natural Scene Understanding:** Categorizing landscapes or scenes for geospatial analysis or environmental monitoring.\n",
    "\n",
    "* **Retail and E-commerce:** Recommender systems, inventory management, and visual search capabilities benefit from image classification.\n",
    "\n",
    "* **Security and Authentication:** Facial recognition for access control or identity verification.\n",
    "\n",
    "These applications illustrate the significance of image classification in various domains, where accurate and efficient categorization of visual data is crucial for decision-making and automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5daf822-82d4-4dc9-be24-ecb453728626",
   "metadata": {},
   "source": [
    "## Setting up the Notebook\n",
    "\n",
    "### Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedbfdcb-e688-4452-9c58-5577d4c6551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision\n",
    "#import torchvision.transforms as transforms \n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1f7a4-f2f2-4249-8156-359dc7e90a18",
   "metadata": {},
   "source": [
    "### Checking/Setting the Computation Device\n",
    "\n",
    "PyTorch allows to train neural networks on supported GPUs to significantly speed up the training process. If you have a support GPU, feel free to utilize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4449d8-75be-4e30-a037-50c2e7cb6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Use this line below to enforce the use of the CPU (in case you don't have a supported GPU)\n",
    "# With this small dataset and simple model you won't see a difference anyway\n",
    "#use_cuda = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(\"Available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f02f84-54eb-4601-9cec-ea725a8a4b0d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d33405-b838-42a1-864e-855d51f36ac2",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "\n",
    "As covered in a different notebook, image preprocessing typically involves two steps\n",
    "\n",
    "* Transforming the raw data to ensure fixed-sized input for the analysis (typically resizing and cropping)\n",
    "\n",
    "* Augmenting the data to create \"new\" data samples to ensure more reliable and stable results\n",
    "\n",
    "To keep things simple in this notebook, we use an already preprocessed dataset containing the images of ships which are labeled with their type (e.g., oil tanker, chemical tanker, container ship, passenger ship). Most importantly all images have already been resized and cropped to a size of 224x224 pixels. The main reason is performance, as resizing images requires additional processing time.\n",
    "\n",
    "Throughout the notebook, we also ignore any data augmentation steps such as flipping/rotating images or changing the colors or color space of images. Again, the main reason here is to focus on the training of an image classifier -- that is, on the basic step without aiming to build the best classifier.\n",
    "\n",
    "Let's look at an example image from the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3ea53-0825-47ef-b25b-1725db088b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('data/images/examples/cruise-ship-02.jpg')\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c7949-99ae-48a4-bcdd-f12b1ca09005",
   "metadata": {},
   "source": [
    "Since all our images are already preprocessed and we do not perform additional augmentation steps, our preprocessing pipeline is limited to transforming images into their tensor representations. That being said, feel free to use some of the augmentation steps as indicated in the code cell below and see if and how it affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074f0db-0f36-4ce7-bee8-fb6d9407ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    #v2.RandomGrayscale(0.50),             # Convert to grayscale image with 50% probability\n",
    "    #v2.ColorJitter(),                     # Adjust the contrast, saturation, hue, brightness, and also randomly permutes channels\n",
    "    #v2.RandomHorizontalFlip(),            # Randomly flip image horizontally\n",
    "    #v2.RandomErasing()                    # Cover images with random balack patches\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de890a4-9678-4b74-b8c5-9dfd6932bb64",
   "metadata": {},
   "source": [
    "## Dataset & Data Loader\n",
    "\n",
    "### Create `Dataset` Object\n",
    "\n",
    "`torchvision.datasets.ImageFolder` is a utility provided by PyTorch's `torchvision` library specifically designed for handling image datasets in a format where each class has its own subdirectory containing the images belonging to that class. Its purpose is to simplify the process of loading and organizing image datasets for machine learning tasks, particularly for tasks involving classification or other forms of supervised learning.\n",
    "\n",
    "Here's what it does:\n",
    "\n",
    "* **Data Loading:** It loads images from a directory structure where each class has its own directory, and each image belongs to a specific class. For example:\n",
    "\n",
    "```\n",
    "    root/class1/xxx.png\n",
    "    root/class1/xxy.png\n",
    "    ...\n",
    "    root/class2/123.png\n",
    "    root/class2/nsdf3.png\n",
    "    ...\n",
    "```\n",
    "    \n",
    "* **Automatic Labeling:** It automatically assigns labels to images based on the directory structure. The subdirectories' names become the class labels, and images within those directories are labeled accordingly.\n",
    "\n",
    "* **Data Transformation:** It allows the application of transformations (such as resizing, cropping, normalization, etc.) to the images before they are used for training, validation, or testing.\n",
    "\n",
    "* **Integration with PyTorch Dataloader:** It integrates seamlessly with PyTorch's DataLoader, enabling efficient loading of images and labels in mini-batches for training neural networks.\n",
    "\n",
    "By using `ImageFolder`, you can avoid manually handling the organization of your image dataset, and it helps streamline the data loading process, making it easier to train machine learning models on image data.\n",
    "\n",
    "The dataset we use in this notebook is already preprocessed to contain only images of vessels of size 224x244 pixels. The dataset is organized into 12 vessel types (i.e., 12 different folders) and contains 5,000 images for each of the 12 vessel types, thus 60,000 images altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd3efc-cc42-4e2f-9655-42438028c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root='/home/vdw/share/data/datasets/shipspotting5k224/', transform=preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a547ce-bf00-45a5-a3c1-ba111945586d",
   "metadata": {},
   "source": [
    "Let's have a look at the 12 different class labels in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b89de-ec26-413d-b560-d8570efd1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edfce29-c957-4399-b8c4-7c4162eb38c0",
   "metadata": {},
   "source": [
    "We can also plot the class distribution using a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1aee14-d541-4cc2-80ed-9675dc8e7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, class_counts = np.unique(dataset.targets, return_counts=True)\n",
    "\n",
    "# creating the bar plot\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.bar(dataset.classes, class_counts, color ='blue', width = 0.4)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacfcd8-be3d-428b-b7f4-c10ff59cb537",
   "metadata": {},
   "source": [
    "Since we already know that we have 5,000 images for each class, the bar chart above is rather boring. However, looking at the class distribution is very useful in practice to check how balanced or imbalanced the class distribution. Here, we kind of have the ideal case as our class distribution is perfectly balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9941676-5223-414a-9f51-8fa370ce0c72",
   "metadata": {},
   "source": [
    "### Create `DataLoader` Objects\n",
    "\n",
    "In PyTorch, the `DataLoader` object is an essential component used for efficiently loading and iterating over datasets during the training or evaluation of machine learning models. It's part of the `torch.utils.data` module and plays a crucial role in handling the data pipeline.\n",
    "\n",
    "Here are its key functionalities:\n",
    "\n",
    "* **Batch Loading:** `DataLoader` divides a dataset into mini-batches. This enables training or evaluating models in batches, which can improve efficiency by utilizing parallelism in hardware like GPUs.\n",
    "\n",
    "* **Shuffling and Sampling:** It allows shuffling of the data within the dataset and facilitates various sampling strategies (random, sequential, etc.) to ensure better training performance and avoid biases during training.\n",
    "\n",
    "* **Parallel Data Loading:** It supports multi-process data loading, where multiple data loading processes can work simultaneously, speeding up the data retrieval process and preventing bottlenecks.\n",
    "\n",
    "* **Integration with Dataset Classes:** It works seamlessly with PyTorch dataset classes (like `torch.utils.data.Dataset` subclasses), which define how to access and preprocess the data.\n",
    "\n",
    "* **Iterating Over Batches:** It provides an iterator over the dataset, allowing easy iteration over mini-batches of data during training or evaluation loops.\n",
    "\n",
    "#### Split Data into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5887b51-1e4a-4cb6-8103-718319034f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set size of traing set to 80% of whole dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "# Set the size of the validation set to the remaining data\n",
    "valid_size = len(dataset) - train_size\n",
    "# split Dataset object into two\n",
    "train_data, valid_data = data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "# Print sizes of training and test set\n",
    "print(\"Number of training images:\\t\", len(train_data))\n",
    "print(\"Number of validation images:\\t\", len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20488a07-7a17-4d4a-a209-7a5ac3aeca2b",
   "metadata": {},
   "source": [
    "### Create `DataLoader` Objects for Training and Validation\n",
    "\n",
    "The code cell below creates the `DataLoader` objects for both the training and the validation data. The main input parameter is the `batch_size` which specifies how many images are in one batch and thus used for a single training step. The parameters `num_workers`, `prefatch_factor`, etc. are mainly to improve the overall performance in terms of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c23be-2f82-418d-92f4-f89f90e11d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, prefetch_factor = 6, pin_memory=True, persistent_workers=True)\n",
    "valid_data_loader = data.DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, prefetch_factor = 6, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db679e0-d7fe-4ec5-bd48-d811714fb196",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cff5db5-64cb-4862-92b3-13abcecf05ec",
   "metadata": {},
   "source": [
    "## Building an Image Classifier\n",
    "\n",
    "### Create CNN Model\n",
    "\n",
    "Sure thing! Convolutional Neural Networks (CNNs) are a specialized type of artificial neural network primarily used for analyzing visual imagery. They're designed to recognize patterns and structures within images by mimicking the visual perception of human beings. What makes CNNs unique is their ability to automatically and adaptively learn spatial hierarchies of features from the input data.\n",
    "\n",
    "At the core of CNNs are convolutional layers, which consist of filters or kernels that slide over the input image, performing mathematical operations (convolutions) to extract specific features. These filters detect various aspects like edges, textures, shapes, and higher-level features as the network progresses through its layers. The network's architecture typically includes multiple convolutional layers interspersed with pooling layers, which reduce the spatial dimensions of the data and extract the most relevant information. By leveraging this hierarchical structure of layers, CNNs can learn increasingly complex representations of the input data. This ability to automatically learn features makes them incredibly powerful for tasks such as image classification, object detection, facial recognition, and more, revolutionizing fields like computer vision and pattern recognition.\n",
    "\n",
    "Let's define a simple CNN to build an image classifier for our vessel image dataset. The model consists of 4 convolutional layers, each followed by a ReLU and MaxPool layer. The last 2 layers, including the output layer, are some liner layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c271b32-c3e2-4449-a2c2-898414c12edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnVesselImageClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        # MaxPool Layer (can be reused for all conv layers)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Hidden linear layer (just one here)\n",
    "        self.fc = nn.Linear(10816, 64)\n",
    "        # Final output layer\n",
    "        self.out = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Push batch through all CONV, RELU, and MAXPOOL layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # Flatten output of last CONV layer\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # Push batch through a hidden layer\n",
    "        x = self.fc(F.dropout(F.relu(x), p=0.5))\n",
    "        # Push batch output layer and return the scores\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c65b1-aa96-4c3c-9e89-dbbf4e596ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnVesselImageClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 16, 3)\n",
    "        # MaxPool Layer (can be reused for all conv layers)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Hidden linear layer (just one here)\n",
    "        self.fc = nn.Linear(10816, 64)\n",
    "        # Final output layer\n",
    "        self.out = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Push batch through all CONV, RELU, and MAXPOOL layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # Flatten output of last CONV layer\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # Push batch through a hidden layer\n",
    "        x = self.fc(F.dropout(F.relu(x), p=0.5))\n",
    "        # Push batch output layer and return the scores\n",
    "        return self.out(x)\n",
    "\n",
    "    \n",
    "# Instatiate model \n",
    "model = CnnVesselImageClassifier(len(dataset.classes)).to(device)\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print model to show the defined layers\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff560c-f8f6-4fbe-b234-7b4f1dd014d8",
   "metadata": {},
   "source": [
    "A basic measure to assess the complexity of a neural network is to look at the number of parameters, i.e., the weights that get updated during the training process. For example, recall that for basic Logistic Regression, the number of parameters (i.e., the $\\theta$ values) was $d+1$, where $d$ was the number of features.\n",
    "\n",
    "We can further distinguish between the total number of parameters and the number of trainable parameters. In some situations, we want that some of the parameters won't be updated. However, for our simple image classifier this is not the case, so the total number of parameters and the number of trainable parameters is the same; see the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14678e6f-71b3-4358-a8a4-99e9830b9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters\")\n",
    "\n",
    "# number of trainable parameters\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d4956-ae12-4111-b084-3d5b761deb09",
   "metadata": {},
   "source": [
    "### Define Auxiliary Methods for Training & Validation\n",
    "\n",
    "The method `train()` in the code cell below implements the basic training loop. The basic training loop for training neural networks involves several fundamental steps that are iteratively performed to train the model. Here's a simplified overview:\n",
    "\n",
    "* **Forward Pass:** For each iteration (epoch) of training: (a) input a batch of training data into the network; (b)perform a forward pass: pass the data through the network's layers from input to output to generate predictions.\n",
    "\n",
    "* **Loss Computation:** Compare the predicted output with the actual target labels using a loss function (e.g., Cross-Entropy, Mean Squared Error). This computes the error or mismatch between predictions and actual values.\n",
    "\n",
    "* **Backpropagation:** Calculate the gradient of the loss function with respect to the network's weights using backpropagation. This involves propagating the error backward through the network to update weights.\n",
    "\n",
    "* **Gradient Descent Optimization:** Update the network's weights to minimize the loss. This involves adjusting weights in the direction that reduces the loss, typically using optimization algorithms like Stochastic Gradient Descent (SGD) or its variants.\n",
    "\n",
    "Of course, the heavy lifting is all done under the hood by PyTorch. The method also computes the current training loss and the current training accuracy. The method `validate()` uses the validation data to compute the current validation loss and the current validation accuracy.\n",
    "\n",
    "While computing the training and validation accuracies for each epoch are not strictly speaking not required to the training itself, they allow us to observe how the accuracies change over time. This is particularly important to spot overfitting, i.e., when the validation accuracy starts to go down again after too many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a04b9-efd2-4711-828f-26ba35008cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss, train_running_correct, counter = 0, 0.0, 0\n",
    "    \n",
    "    for i, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "        counter += 1\n",
    "        image, labels = data\n",
    "        \n",
    "        # Move batch to device (CPU or GPU)\n",
    "        image, labels = image.to(device), labels.to(device)\n",
    "        \n",
    "        # Push batch through model\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "        ### Pytorch magic! ###\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss / counter\n",
    "    epoch_acc = 100. * (train_running_correct / len(loader.dataset))\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# validation\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss, valid_running_correct, counter = 0, 0.0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(loader), total=len(loader)):\n",
    "            counter += 1            \n",
    "            image, labels = data\n",
    "            \n",
    "            # Move batch to device (CPU or GPU)\n",
    "            image, labels = image.to(device), labels.to(device)\n",
    "            \n",
    "            # Push batch through model\n",
    "            outputs = model(image)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(loader.dataset))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52f971-7255-42fe-a08b-dd71cce0ce06",
   "metadata": {},
   "source": [
    "### Network Training\n",
    "\n",
    "We now have everything in place to actually training our vessel image classifier. Let's first define a few auxiliary lists to keep track of all training and validation losses and accuracies. With those, you can run the training loop below multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1f872-a765-4cc1-9f12-99be0693ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to keep track of losses and accuracies\n",
    "train_loss, valid_loss = [], []\n",
    "train_acc, valid_acc = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e5cef-4cf1-4f5c-945e-a439671b36df",
   "metadata": {},
   "source": [
    "The code cell below trains our model for several epochs. In each epoch, it first calls the `train()` and then the `validate()` method. The code below prints the training and validation losses and accuracies for each epoch as well as keeps track of all losses and accuracies in the case you run the code cell below multiple times to train the model for further epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47381170-e3b0-4ee6-b381-88d2fed7f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "# start the training\n",
    "for epoch in range(epochs):\n",
    "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_acc = train(model, train_data_loader, optimizer, criterion)\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(model, valid_data_loader, criterion)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    valid_loss.append(valid_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
    "    print('-'*50)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a930f-e158-4f88-a7ba-a736260842b1",
   "metadata": {},
   "source": [
    "### Visualization of Results\n",
    "\n",
    "As a last step, we can now look at the result in terms of how the losses and accuracies change over time, i.e., across epochs. Since we keep track of all losses and accuracies in lists, we can quickly create a basic line chart to visualize those trends. First, let's  look at the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27829783-3157-42b3-ade5-853da419cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(train_loss))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, train_loss, label='training loss')\n",
    "plt.plot(x, valid_loss, label='validation loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e787c87-53ca-47f6-bb54-5653e82f4e9c",
   "metadata": {},
   "source": [
    "And here's the plot with the training and validation accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4e5e1-7ff8-48d5-849d-3102baac32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(x, train_acc, label='training accuracy')\n",
    "plt.plot(x, valid_acc, label='validation accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04a940-df80-41fe-a347-09243f50c12e",
   "metadata": {},
   "source": [
    "When looking at both plots, we can see a typical training behavior: On the one hand the training results continue to improve for a very long time, while the validation results start to plateau and even get worse at some point. This is what is commonly referred to as overfitting, i.e., when the model starts learning \"too much\" (the noise and the training data) leading to a poorer generalization on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a018b-edea-49cc-bb2b-87b9d91960a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb163ee9-1dce-43c3-91fd-64b327e604fa",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Building image classifiers using convolutional neural networks (CNNs) involves leveraging deep learning techniques specifically designed for image recognition tasks. CNNs excel in identifying patterns within images by using a hierarchical structure of layers that progressively extract features from the input data.\n",
    "\n",
    "The architecture typically consists of convolutional layers, pooling layers, and fully connected layers. Convolutional layers apply filters to the input image, detecting features like edges or textures. Pooling layers reduce the spatial dimensions of the data, preserving the most important information. Finally, fully connected layers process the extracted features to make predictions.\n",
    "\n",
    "Training a CNN involves feeding it labeled images, adjusting the network's parameters (weights and biases) through forward and backward propagation to minimize prediction errors. Transfer learning is often employed, utilizing pre-trained CNN models on vast image datasets like ImageNet to leverage their learned features and fine-tune them for specific tasks with smaller datasets.\n",
    "\n",
    "To evaluate a CNN's performance, metrics like accuracy, precision, recall, and F1-score are commonly used. Data augmentation techniques, such as rotation, flipping, or scaling images, can enhance model generalization by exposing it to more diverse data.\n",
    "\n",
    "Continuous advancements in CNN architectures, regularization techniques, and optimization algorithms contribute to improving the accuracy and efficiency of image classifiers, enabling their application across various domains like medical imaging, autonomous vehicles, and facial recognition systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1259bbf-4e35-4625-917c-499e58c7bfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310]",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
