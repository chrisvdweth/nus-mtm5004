{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d377ab28-824a-48be-a007-e59eee57dbc1",
   "metadata": {},
   "source": [
    "<img src=\"data/images/div/lecture-notebook-header.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f877b1",
   "metadata": {},
   "source": [
    "# Preparation: NumPy\n",
    "\n",
    "The programming language of choice for CS5228 is Python. Python is a very popular language that is -- in comparison to other languages -- easy to read, easy to write, and thus easy to learn. Ideally, you already have some hands-on experience with Python from previous modules or simply by working on your own scripts and programs. This course cannot introduce Python to beginners. If needed, however, the popularity of Python resulted in a wider range of excellent tutorials that are freely available online (incl. comprehensive courses on YouTube).\n",
    "\n",
    "Python has originally not been designed for \"number crunching\", i.e., numerical computations over large volumes of data. However, its popularity and widespread adoption spurred then development of highly optimized packages. These packages are written in \"fast\" programming languages such as C/C++ and provide bindings to be used in Python programs. One of the most important packages is [NumPy](https://numpy.org/). Directly taken from the website:\n",
    "\n",
    "* Fast and versatile, the NumPy vectorization, indexing, and broadcasting concepts are the de-facto standards of array computing today.\n",
    "* NumPy offers comprehensive mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more.\n",
    "* NumPy supports a wide range of hardware and computing platforms, and plays well with distributed, GPU, and sparse array libraries.\n",
    "* The core of NumPy is well-optimized C code. Enjoy the flexibility of Python with the speed of compiled code.\n",
    "* NumPyâ€™s high level syntax makes it accessible and productive for programmers from any background or experience level.\n",
    "\n",
    "In short, NumPy enables number crunching with Python, and also forms the foundation for other packages supporting data analysis and data visualization. In this tutorial, we explore the basic features of NumPy to acknowledge and appreciate its power and benefits.\n",
    "\n",
    "Let's get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4278852",
   "metadata": {},
   "source": [
    "## Setting up the Notebook\n",
    "\n",
    "### Import Required Packages\n",
    "\n",
    "The focus here is of course on NumPy. The `sys` package is only needed for a quick example later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Using the alias np is not needed but very commonly and almost standard\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151e1e4",
   "metadata": {},
   "source": [
    "### Set Print Options\n",
    "\n",
    "NumPy allows to print multidimensional arrays, by default with high precision and in scientific notation. To make the output easier to read, we limit the output to 4 decimal places and do not use the scientific notations. Feel free to remove this line and see how the output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcedca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569de723-15aa-4b8b-bb4a-d7380a64ff39",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfc974",
   "metadata": {},
   "source": [
    "## Arrays\n",
    "\n",
    "The core concept of NumPy are homogeneous multidimensional arrays. That means, an array is a grid of (typically numerical) entries, all of the same type. While Python already allows to create grids using lists of lists, NumPy arrays are a much more powerful concept for scientific computing due highly optimized implementation and methods to index and manipulate arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333363b",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5eaa48",
   "metadata": {},
   "source": [
    "#### Creating Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff5044",
   "metadata": {},
   "source": [
    "[`np.array()`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) creates a NumPy array given an \"array-like\" or \"grid-like\" input. This is most commonly a normal list of lists. However, note that the following 2 requirements need to be fulfilled:\n",
    "\n",
    "* All elements have the same type (NumPy may perform some automated casting if needed); normal Python list can contain elements of different data types\n",
    "\n",
    "* All lists of the same dimensions must have the same length, i.e., the grid must be \"complete\".\n",
    "\n",
    "The commented examples below should make this clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_list =  [[2, 0, 1], [1, 3, 2]]     ## Correct format: conistent lengths, same datatype (here: int)\n",
    "#py_list =  [[2, 0, 1], [1, 3, 2.0]]   ## Acceptable format: conistent lengths, all entries treated as floats/double\n",
    "#py_list =  [[2, 0, 1], [1, 3]]        ## Inconsistent sizes: result is not a 2d array but 1d array with lists as entries\n",
    "#py_list =  [[2, 0, 1], [1, 3, '2']]   ## Different data types: all entries are treated as string\n",
    "\n",
    "a = np.array(py_list)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8b1f0",
   "metadata": {},
   "source": [
    "It is also possible to specify the data type of the array elements. We can use the same example from above containing only integer values but create an array of float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38525c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[2, 0, 1], [1, 3, 2]], dtype=float)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36e23e",
   "metadata": {},
   "source": [
    "While 2d array are easier to print and to interpret, NumPy arrays can have multiple dimensions (called **axes**). The following example creates a 3d array, so the input grid is a list of lists of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093815fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[2, 0, 1], [1, 3, 2]], [[4, 4, 6], [3, 5, 1]]])\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967d525",
   "metadata": {},
   "source": [
    "#### Describing Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[2, 0, 1], [1, 3, 2]], [[4, 4, 6], [3, 5, 1]]], dtype=np.int64)\n",
    "#a = np.array([[[2, 0, 1], [1, 3, 2]], [[4, 4, 6], [3, 5, 1]]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58614ec",
   "metadata": {},
   "source": [
    "[`np.array.ndim`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.ndim.html) returns the number of dimensions (axes) of a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ce9a5",
   "metadata": {},
   "source": [
    "[`np.array.dtype`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.dtype.html) returns the data type of the elements in a NumPy array. More information about NumPy data types can be found [here](https://numpy.org/doc/stable/reference/arrays.dtypes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c201e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ec6c7",
   "metadata": {},
   "source": [
    "The choice of the data type affects the physical size of an array in memory. For example, an `int64` element requires 8 bytes while an `int32` element requires only 4 bytes. This is particularly important for very large arrays as it can make the difference if they fit into the main memory or not.\n",
    "\n",
    "The statement below shows the number of bytes for array `a`. Try different data types when creating `a` and see how it affects its size in memory. However, note that a NumPy array is an object with more than just the elements. So an `int32` array won't be half the size of an `int64` array, particularly when the number of elements is rather small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.getsizeof(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813b2df",
   "metadata": {},
   "source": [
    "[`np.array.shape`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html) returns the shape of a NumPy array, i.e., the size if the different dimensions (axes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbd068",
   "metadata": {},
   "source": [
    "### Auxiliary Methods for Array Creation\n",
    "\n",
    "NumPy provides a wide range of methods to create new arrays. The following examples give an overview of the most common ones. Note that all the examples below create 2d arrays to keep it simple. However, methods that take the shape of the newly created array as input parameter can be used to create arrays with arbitrary numbers of dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a921bae",
   "metadata": {},
   "source": [
    "[`np.zeroes`](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html) creates an array with all entries being 0; a common way to initialize an array. The main input parameter is the `shape` as tuple of the resulting array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4745a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((3,5))\n",
    "\n",
    "print(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b90e2b",
   "metadata": {},
   "source": [
    "[`np.ones`](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) creates an array with all entries being 1. The main input parameter is the `shape` as tuple of the resulting array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc4834",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((3,5))\n",
    "\n",
    "print(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ddcd7",
   "metadata": {},
   "source": [
    "[`np.full`](https://numpy.org/doc/stable/reference/generated/numpy.full.html) creates an array with all entries being a specified value. The main input parameters are the `shape` as tuple of the resulting array, as well as the value to be used as initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full((3,5), 5.8)\n",
    "\n",
    "print(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938e491",
   "metadata": {},
   "source": [
    "[`np.random.rand`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html) creates an array with all entries being random values between 0 and 1. The main input parameter is the `shape` of the resulting array. There a several related methods to generates random values, e.g., [`np.random.randint`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html), [`np.random.randn`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html), and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e813de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(3,5)\n",
    "\n",
    "print(a)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147fae9",
   "metadata": {},
   "source": [
    "[`np.eye`](https://numpy.org/doc/stable/reference/generated/numpy.eye.html) creates an array representing an identity matrix. The main input parameter is the size of the matrix. Note that that an identity matrix is square 2d matrix, so a single integer value is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.eye(3)\n",
    "\n",
    "print(a)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02da8c-e2a5-4a60-ab1e-9ed8de51179c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be2bfb",
   "metadata": {},
   "source": [
    "## Array Manipulation\n",
    "\n",
    "NumPy provide a [series of useful methods](https://numpy.org/doc/stable/reference/routines.array-manipulation.html) to manipulate arrays, where the manipulation does not involve changing individual elements but rather the shape of the array. Here we cover just some of the most commonly used methods.\n",
    "\n",
    "Let's use the same example array again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba081e7c",
   "metadata": {},
   "source": [
    "[`np.transpose()`](https://numpy.org/doc/stable/reference/generated/numpy.transpose.html) reverses or permutes the axes of an array. In case of matrices (i.e., 2d arrays) `transpose()` calculates the common matrix transpose known from your Math classes. Since it's such a common operation, there's also the shorthand notation using `T`. As our example array `a` is a matrix, the following operations all perform the same matrix transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48101619",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.T\n",
    "#a.transpose()\n",
    "#np.transpose(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3322bd2",
   "metadata": {},
   "source": [
    "[`np.reshape()`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) changes the shape of an array without changing the data. As such, this method requires as input parameter the new shape. Of course, the new shape must be compatible with the old shape -- that is, the product of all dimensions must remain the same. For example, array `a` has the shape `(3, 4)`. This means we can reshape it to `(1, 12)`, `(12, 1)`, `(2, 6)`, `(6, 2)`, `(3, 2, 2)`, etc. as the product of all dimensions is always 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13765902",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(6,2)\n",
    "#np.reshape(a, (6,2))   # Same effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69097c88",
   "metadata": {},
   "source": [
    "As long as the products of the dimensions match, the number of dimensions for the new shape do not matter -- see the examples below. Of course, in practice, reshaping should result in meaningful new arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the commands below will work just fine.\n",
    "a.reshape(1,1,6,1,1,2,1,1)\n",
    "#a.reshape(2,1,3,2,1)\n",
    "#a.reshape(1,12)\n",
    "#a.reshape(1,1,12)\n",
    "#a.reshape(1,1,1,12)\n",
    "#a.reshape(1,1,1,1,12)\n",
    "#a.reshape(1,1,1,1,1,12)\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942024c7",
   "metadata": {},
   "source": [
    "Just to give an example, the following reshaping fails since the product of the dimensions of the new shape is not 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802af3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.reshape(2, 1, 5)  # <-- This will fail\n",
    "#a.reshape(2, 1, 6)  # <-- That will work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44165fb9",
   "metadata": {},
   "source": [
    "In practice the size of an array may not be known ahead of time making it difficult to guarantee a new shape will be valid. `np.reshape()` therefore accepts a special dimension size `-1` to tell the method to calculate the required size of the dimensions automatically.\n",
    "\n",
    "The most common use case is to flatten a multidimensional array into a 1d array. Here, we do not really care about the number and size of all dimensions. We only want a new array with the shape `(1, \"rest\")`. We can does this for our example array `a` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c024ade",
   "metadata": {},
   "source": [
    "The `-1` parameter can als be used in different pThe `-1` parameter can also be used in different parts of the new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.reshape(2, -1, 2)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088e1bc",
   "metadata": {},
   "source": [
    "It is easy to see that `-1` can only be used once, otherwise the calculation of the missing dimensions would generally be ambiguous. Also, it must be possible to find the missing dimension to ensure that the products of dimensions will match. As such, the following to uses will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.reshape(-1, 3, -1)   # ValueError: can only specify one unknown dimension\n",
    "#a.reshape(-1, 3, 3)    # ValueError: cannot reshape array of size 12 into shape (3,3) -- 3*3*?=12 does not work out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693389a3-8652-4171-ae69-150a344ccfd2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9c7bd",
   "metadata": {},
   "source": [
    "## Array Indexing\n",
    "\n",
    "Array indexing refers to the process of accessing and manipulating elements of an array using various indexing techniques. NumPy provides powerful indexing capabilities that allow you to retrieve specific elements, subsets, or modify values within an array. Array indexing in NumPy can be done using different methods:\n",
    "\n",
    "* **Integer indexing:** Integer indexing allows you to access individual elements or subsets of an array by specifying the indices explicitly. You can use a single integer to access a specific element or use an array of integers to access multiple elements simultaneously.\n",
    "\n",
    "* **Slicing:** Slicing is a common indexing technique that allows you to extract a contiguous portion of an array. It involves specifying a range of indices using the colon (:) symbol. Slicing can be used to retrieve rows, columns, or sub-arrays from a larger array.\n",
    "\n",
    "* **Boolean indexing:** Boolean indexing enables you to select elements from an array based on a given condition or a boolean mask. You can create a boolean mask by applying a logical condition to the array, and then use the mask to extract elements that satisfy the condition.\n",
    "\n",
    "* **Fancy indexing:** Fancy indexing refers to indexing an array using an array of indices or a boolean mask. It allows for advanced indexing operations, such as selecting specific rows or columns in a specific order or combining multiple indexing techniques.\n",
    "\n",
    "Array indexing in NumPy is highly flexible and allows for both read and write operations. You can access and modify individual elements, extract subsets, or assign new values to specific locations within an array. This versatility makes array indexing a powerful tool for data manipulation and analysis.\n",
    "\n",
    "We will use the same example array `a` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b48597",
   "metadata": {},
   "source": [
    "### Indexing Individual Elements\n",
    "\n",
    "The most basic way to access array elements is by using scalar value to express the array indices. This is similar to indexing basic lists of lists in Python but also provides a simplified and more convenient notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[2][1]  # Notation for basic Python lists of lists; valid notation for NumPy arrays as well but less common\n",
    "\n",
    "a[2,1]  # More common and more convenient notation for NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47db5b",
   "metadata": {},
   "source": [
    "To get, say, the first column of `a`, we first have to understand slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ba9ca",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "Slicing refers to indexing all elements in an array from one given index to another given index, optionally including a step size to ignore certain indices between the start and end index. The general format of a slice is `[start:end]` (and `[start:end:step]` if a step size larger than 1 needs to be specified.\n",
    "\n",
    "A slice indexes the elements with respect to only one dimension (axis). So an $n$-dimensional array may require the definition of $n$ slices. Our example array `a` is a 2d-array of shape `(3,4)`. To get the first 2 rows, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6325cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "a[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418575c",
   "metadata": {},
   "source": [
    "The following example returns only every other row. For this, we set the step size to 2. Since we do not make any restrictions on the start and end index, we can simply leave them empty (we can set the the start index to 0; no harm in that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c789b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[::2]\n",
    "#a[0::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5d7c6",
   "metadata": {},
   "source": [
    "Now let's assume we want not the first 2 rows but the first 2 columns. This requires slicing with respect to the 2nd dimensions (axis). This implies that we have to specify that first 2 values of *all* rows, which we can do by using a non-restrictive slice for the 1st dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb89701",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0:2]\n",
    "#a[::,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7253340",
   "metadata": {},
   "source": [
    "**Note:** Instead of `a[0:2]` to get the first 2 rows, we could also write `a[0:2,:]`, i.e., specifying a non-restrictive slice on the 2nd dimension. However, here it is not mandatory since it can be unambiguously  derived.\n",
    "\n",
    "Of course, we can use restrictive slices regarding all dimensions, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93902e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0:2,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486df42b",
   "metadata": {},
   "source": [
    "As it is already common for standard Python lists, the indexing can also be done with respect to the end of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-2:,-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231883b3",
   "metadata": {},
   "source": [
    "These different ways of slicing can be arbitrarily combined to extract the relevant elements from an array. The example below returns for every other column the first 2 row values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0:2,::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c85cc9",
   "metadata": {},
   "source": [
    "Since slicing uses only `start`, `end` and `step` for indexing, the result will always be a subarray of the original array. That means, for example, it is not possible to return an array with an arbitrary order of the elements for each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41a40b",
   "metadata": {},
   "source": [
    "### Integer Array Indexing\n",
    "\n",
    "Instead of individual integers or `[start:end:step]` slices, we can use lists/arrays of integers to index elements of one dimension (axis). This allows us to index an arbitrary subset of elements in an arbitrary order. The following example extracts the second and third row but also changes their order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f051b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[2,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aaedaa",
   "metadata": {},
   "source": [
    "Using non-restrictive slices, we can do the same for other axes, for example to extract the first 2 columns and change their order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a754025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "a[:,[0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1acd9",
   "metadata": {},
   "source": [
    "Again, one can combine integer array indexing of multiple axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba055df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[[2,1], [0,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec2a64",
   "metadata": {},
   "source": [
    "This result is arguably not that intuitive. It becomes more clearer when the integer array indexing is rewritten as a multiple basic integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([a[2,0], a[1,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b201380",
   "metadata": {},
   "source": [
    "This implies that the 2 arrays used for indexing the 2 axes have to be of the same length. For example, the following statement will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a[[2,1], [0,3,1]]   # np.array([a[2,0], a[1,3], a[?,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e32214",
   "metadata": {},
   "source": [
    "### Boolean Indexing\n",
    "\n",
    "Boolean indexing allows us to find elements based on a given condition. A boolean index is an array of the same shape as the input array with all elements being `True` (element fulfills condition) or `False` (element does not fulfill condition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_index = (a > 5)\n",
    "\n",
    "print(boolean_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151add8c",
   "metadata": {},
   "source": [
    "Now this boolean index can be used to get all the elements from the initial array where the respective element in the boolean index is `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[boolean_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3927d1",
   "metadata": {},
   "source": [
    "Note that the resulting array is a 1d-array since the distribution of `True` and `False` values generally does not induce a valid multidimensional array structure (see the example `boolean_index` above).\n",
    "\n",
    "In practice, the two statements above can be combined into one to make the code more concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f407fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9781421",
   "metadata": {},
   "source": [
    "The indexing supported by NumPy is quite powerful and the examples only provide a basic introduction. You can check the [documentation](https://numpy.org/doc/stable/reference/arrays.indexing.html) for more details about indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c3d22-bcc1-480a-9a96-e7e7978e2ed0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c640b",
   "metadata": {},
   "source": [
    "## Array Math\n",
    "\n",
    "The purpose of array math in NumPy is to perform mathematical operations efficiently and element-wise on arrays. NumPy provides a powerful and efficient mathematical computation framework, allowing you to perform operations on arrays with ease. Array math in NumPy serves several important purposes:\n",
    "\n",
    "* **Efficient computation:** NumPy is built on highly optimized C code, which makes it significantly faster than traditional Python operations on individual elements. Array math in NumPy leverages this efficiency to perform mathematical computations on entire arrays at once. This allows for faster execution and improved performance, especially when dealing with large datasets or complex computations.\n",
    "\n",
    "* **Element-wise operations:** Array math in NumPy applies mathematical operations element-wise, meaning that the operations are performed on corresponding elements of the arrays. This behavior enables convenient and concise syntax for performing mathematical operations on entire arrays without the need for explicit loops. It simplifies the code and improves readability.\n",
    "\n",
    "* **Broadcasting:** NumPy's broadcasting feature allows for implicit expansion of arrays to match sizes and shapes during mathematical operations. This capability allows operations to be performed between arrays of different sizes or dimensions. Broadcasting eliminates the need for explicitly reshaping or replicating arrays, making array math more flexible and convenient.\n",
    "\n",
    "* **Numerical computation:** NumPy provides a wide range of mathematical functions and operators that cover various mathematical operations, including arithmetic operations, trigonometric functions, logarithmic functions, statistical functions, linear algebra operations, and more. These functions enable complex numerical computations and facilitate advanced data analysis and scientific computing tasks.\n",
    "\n",
    "* **Integration with other libraries:** NumPy serves as the foundation for many scientific computing libraries and frameworks in Python, such as SciPy, Pandas, and scikit-learn. Array math in NumPy allows for seamless integration with these libraries, enabling efficient computation and data manipulation across the entire data science ecosystem.\n",
    "\n",
    "Let's create 2 example arrays to illustrate the effects of different array math operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1792bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4], [2, 2, 3, 3]])\n",
    "b = np.array([[4, 1, 1, 2], [1, 4, 2, 2]])\n",
    "\n",
    "print(a)\n",
    "print()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a2276",
   "metadata": {},
   "source": [
    "### Elementwise Operations\n",
    "\n",
    "If two arrays have the same shape, arithmetic operations (+, -, \\*, /, %) between the two arrays are applied to the two elements in the same respective positions in the arrays.\n",
    "\n",
    "#### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12a503",
   "metadata": {},
   "source": [
    "#### Substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2083d1",
   "metadata": {},
   "source": [
    "#### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01828ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d15de",
   "metadata": {},
   "source": [
    "#### Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e5798",
   "metadata": {},
   "source": [
    "#### Modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a % b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052dd0a",
   "metadata": {},
   "source": [
    "The application of NumPy methods implementing unary mathematical operations are also applied to the elements of an array, for example:\n",
    "\n",
    "#### Square Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cf770",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47961492",
   "metadata": {},
   "source": [
    "#### Sinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6e365-cc1d-41b1-87ed-1e7b29bc27b0",
   "metadata": {},
   "source": [
    "Of course, these are just two examples for unary operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe0ef0",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Broadcasting allows us to perform arithmetic operations on arrays of different shapes (compared to element-wise operations which require arrays of the same shape). Of course, two arrays cannot have completely arbitrary shapes to result in a meaningful operation between them. When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\n",
    "\n",
    "* they are equal, or\n",
    "\n",
    "* one of them is 1\n",
    "\n",
    "For more details, check out the [documentation on broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399a117",
   "metadata": {},
   "source": [
    "#### Example: Addition\n",
    "\n",
    "First let's create a simple column vector with two elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30478cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = np.array([[1], [3]])\n",
    "\n",
    "print(col)\n",
    "print()\n",
    "print(\"Shape of column vector:\", col.shape)\n",
    "print(\"Shape of matrix s:\", a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba1eff",
   "metadata": {},
   "source": [
    "Since all dimensions of `col` and `a` are compatible according to the definition above, we can broadcast `col` when adding it to `a`. This means that we add 1 to all elements of the first row and 2 to all elements of the second row of `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "print(a + col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0696f05",
   "metadata": {},
   "source": [
    "We can do the same with a row vector where we want to add, say, 2/4/6/8 to the first/second/third/fourth column of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.array([2, 4, 6, 8])\n",
    "\n",
    "print(row)\n",
    "print()\n",
    "print(\"Shape of row vector:\", row.shape)\n",
    "print(\"Shape of matrix a:\", a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c4aba",
   "metadata": {},
   "source": [
    "Notice that `row` and `a` do not have the same number of dimensions. However, broadcasting is still possible since we start with the trailing (i.e. rightmost) dimensions to check if they are compatible. This is true here since the rightmost dimensions of both arrays is of size 4, and that's the only dimension that needs to be compatible as `row` has only 1 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd66001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "print(a + row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be30d6c",
   "metadata": {},
   "source": [
    "Of course, broadcasting is not limited to addition but is supported for all other arithmetic operations (arithmetic operations (+, -, \\*, /, %)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5fa65",
   "metadata": {},
   "source": [
    "### In-Built Math Functions\n",
    "\n",
    "NumPy provides a [long list of mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html) to perform computations on arrays. \n",
    "\n",
    "\n",
    "#### Elementwise functions\n",
    "\n",
    "Many of them apply mathematical operations on each element of an array, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd844d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Calculate the square root of all elements:\")\n",
    "print(np.sqrt(a))\n",
    "print()\n",
    "\n",
    "print(\"Calculate the log of all elements:\")\n",
    "print(np.log(a))\n",
    "print()\n",
    "\n",
    "print(\"Calculate the exponential of all elements:\")\n",
    "print(np.exp(a))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b22ac",
   "metadata": {},
   "source": [
    "Note that the element-wise arithmetic operations mentioned above can also be expressed using in-built functions. For example, `a + b` yields the same result as `np.add(a, b)`.\n",
    "\n",
    "\n",
    "#### Aggregation Functions\n",
    "\n",
    "Other functions perform aggregation operation (min, max, mean, sum, etc.) over arrays. This can be done over all elements in the array or with respect to a specified dimension. Let's use [`np.sum()`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) as an example.\n",
    "\n",
    "First, we can sum up all the elements in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21730ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Calculate the sum of all elements:\")\n",
    "print(np.sum(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876ebee",
   "metadata": {},
   "source": [
    "By specifying `axis=0`, we can sum elements with respect to the first dimensions. This means, we sum the first element of all rows, the second element of all rows, and so on. Hence the result is not a single number but an array with all the sums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd256c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Calculate the sum of all columns:\")\n",
    "print(np.sum(a, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc543c6e",
   "metadata": {},
   "source": [
    "Of course, we can perform the same for the columns with `axis=1`, summing up all elements of the for row, summing up all elements of the second row, and so on...well, our example array `a` has only 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96015eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(\"Calculate the sum of all rows:\")\n",
    "print(np.sum(a, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2121a297",
   "metadata": {},
   "source": [
    "#### Non-Element-wise Array Operations\n",
    "\n",
    "While `*` refers to the elementwise multiplication between two NumPy arrays, in Math this operation typically refers to the dot product between matrices or vectors. NumPy provides the [`np.dot()`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html) method for this. Let's assume we want to calculate the following matrix-vector multiplication.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\t1 & 2 & 3 & 4  \\\\\n",
    "\t2 & 2 & 3 & 3\n",
    "\\end{bmatrix}\n",
    "* \\begin{bmatrix}\n",
    "\t1 \\\\\n",
    "\t2 \\\\\n",
    "\t3 \\\\\n",
    "\t4\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "\t30 \\\\\n",
    "\t27\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The respective code in NumPy looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create the column vector\n",
    "col = np.array([[1], [2], [3], [4]])\n",
    "\n",
    "print(\"Dot product:\")\n",
    "print(np.dot(a, col))\n",
    "#print(a.dot(col))      # Same effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b5ff9-43d4-4168-897a-6b572112405a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c2858",
   "metadata": {},
   "source": [
    "## Arg* Methods\n",
    "\n",
    "We already saw that NumPy comes with methods that return the minimum, maximum, mean, etc. value(s) in an array. However, there are many use cases where not the value itself (e.g., the minimum) but where in the array the minimum is located (see \"Finding the K-Nearest Neighbors\" use case below). To this end, Numpy provides different arm* methods.\n",
    "\n",
    "Let's first create a `(3, 5)` array with random integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(1, 20, size=(3, 5))\n",
    "\n",
    "print(a)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c06284",
   "metadata": {},
   "source": [
    "[`np.argmax()`](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) returns the indices of the maximum values along an axis (if a axis is specified). First let's find the index of the largest element in `a` overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(a)\n",
    "\n",
    "print(max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c730242",
   "metadata": {},
   "source": [
    "Note that the index is scalar value and not a 2d index as might be expected. The index 5 reflects the position of the value of `a` would be flattened to a 1d array. Hence, we can get the maximum value by flatten `a` and get the value at position `max_idx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reshape(-1)[max_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798610f",
   "metadata": {},
   "source": [
    "Also note that `np.argmax()` also returns just one value although multiple elements in `a` have the largest value of 9. The returned index is the index of the first occurrence of the max value.\n",
    "\n",
    "As mentioned above, we can also get the indices of the maximum values with respect to axes. In this case, we get multiple indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc85eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(np.argmax(a, axis=0))\n",
    "print()\n",
    "\n",
    "print(np.argmax(a, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0d8a6",
   "metadata": {},
   "source": [
    "For example, the result `[1 0 1 1 2]` shows the indices of the 5 maximum values for the 5 columns of `a`. Since the first column is `[5 9 4]`, the maximum value is at index 1, represented by `[1 ...]` and so on.\n",
    "\n",
    "[`np.argmin()`](https://numpy.org/doc/stable/reference/generated/numpy.argmin.html) works exactly the same just for finding the indices of the minimum values.\n",
    "\n",
    "[`np.argsort()`](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html) returns the indices that would sort an array. That means, this method sorts the element in the array but then returns the indices and not the actual values. In contrast to `np.argmax()` and `np.argmin()`, `np.argsort()` sort with respect to the last dimension (`axis=-1`) by default. So to sort irregardless of an axis, one has to explicitly set `axis=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc5f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(np.argsort(a, axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1792",
   "metadata": {},
   "source": [
    "Again, the order of indices reflects a flatted version of the input array. For example, there are four 1's (smallest value) in `a` at the indices 1, 3, 6, and 11 if a would be flattened to an 1d array. When setting `axis=-1` or any other valid value -- here either 0 or 1 since `a` has only 2 dimensions -- we get the indices that would sort the values with respect to the chosen dimension/axis. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c60048",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)\n",
    "print()\n",
    "\n",
    "print(np.argsort(a, axis=1))\n",
    "#print(np.argsort(a, axis=-1)) # Same effect since a has only to axes 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6f5be",
   "metadata": {},
   "source": [
    "This result tells us that, e.g., for the first row, the smallest value is at index 1 and the largest value at index 0. If multiple elements with the same value the order in the sorted result depends on the order of occurrence. For example, there are two 1's (smallest value) in the first row, so the first one at index 1 will come before the one at index 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a1512-4d21-4dbc-86d7-e6fc6c432e9a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b6bd2",
   "metadata": {},
   "source": [
    "## Practical Example Use Cases\n",
    "\n",
    "When you're new to NumPy (or data science with Python, in general), the usefulness and power of indexing, slicing, broadcasting, and so on are unlikely to be very obvious from just going through this notebook so far and running the basic examples. The benefits of NumPy really begin to shine when actually using it to solve problems and perform computation that utilize NumPy arrays. Therefore, in the last part of the notebook, we go through some concrete use cases to see how NumPy can make our lives easier. The two use cases are still very simple, but should still be able to appreciate that solving using NumPy yields a shorter and cleaner implementation -- in practice, typically also a much faster one, but given the toy data we use here, you won't see a noticeable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c76d7e",
   "metadata": {},
   "source": [
    "### Finding the K-Nearest Neighbors\n",
    "\n",
    "The k-nearest neighbors (k-NN) are data points in a dataset that are most similar or closest to a given query point in a feature space. In the k-NN algorithm, the k nearest neighbors are identified based on a distance metric, such as Euclidean distance or cosine similarity. These neighbors play a crucial role in making predictions or determining the similarity of the query point. The k-nearest neighbor (k-NN) problem is a widely used algorithm in machine learning and data mining. It is a non-parametric method used for classification and regression tasks. Some common applications of the k-NN problem include:\n",
    "\n",
    "* **Classification:** k-NN can be used for classifying data points into different categories. Given a new data point, the algorithm identifies the k nearest neighbors based on a distance metric (such as Euclidean distance) and assigns the class label that is most common among its k nearest neighbors.\n",
    "\n",
    "* **Regression:** In addition to classification, k-NN can also be used for regression tasks. Instead of assigning class labels, the algorithm estimates the value of a target variable based on the average or weighted average of the target values of its k nearest neighbors.\n",
    "\n",
    "* **Recommender systems:** k-NN can be applied to recommend items to users based on their similarity to other users or items. For example, in collaborative filtering, the algorithm can find similar users and recommend items that those similar users have liked or purchased.\n",
    "\n",
    "* **Anomaly detection:** k-NN can be used to identify outliers or anomalies in a dataset. The algorithm measures the distance of a data point to its k nearest neighbors, and if a point is significantly distant from its neighbors, it can be considered as an anomaly.\n",
    "\n",
    "* **Image recognition:** k-NN can be used in image recognition tasks. Given an input image, the algorithm can compare it with a set of labeled images to determine the class label of the input image based on the labels of its k nearest neighbors.\n",
    "\n",
    "* **Text classification:** k-NN can be applied to classify text documents based on their similarity. By representing documents as vectors, such as using the term frequency-inverse document frequency (TF-IDF) representation, the algorithm can find the k most similar documents and assign a class label based on those neighbors.\n",
    "\n",
    "These are just a few examples of the many applications of the k-nearest neighbor problem. Its simplicity and effectiveness make it a popular choice in various fields where pattern recognition and similarity-based analysis are required. For the following example, we create a random dataset `D` of 10 data points, with each data point featuring 5 attributes/features/coordinates. This means that `D` can be represented as a matrix (2d array) of shape `(10, 5)`. We also need a data point `x` for which we want to find the k-nearest neighbors. Naturally, `x` must have the same number of 5 attributes/features/coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10) # Just to ensure that we get the same random numbers\n",
    "\n",
    "D = np.random.rand(10, 5)\n",
    "x = np.random.rand(5)\n",
    "\n",
    "print('Dataset D:')\n",
    "print(D) \n",
    "print()\n",
    "print('Data point x:')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907229c3",
   "metadata": {},
   "source": [
    "Given `x`, we now want to find the, say, 3 most similar data points, i.e., its 3-nearest neighbors. Since we have numerical features, we can directly apply the Euclidean distance to measure the similarity between two data points. Given two multidimensional data points `p` and `q` with `n` number of features., The Euclidean Distance `d(p, q)` is defined as:\n",
    "\n",
    "$$\n",
    "d(p, q) = \\sum_{i=1}^n \\sqrt{(p_i - q_i)^2} = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + ... (p_n - q_n)^2 }\n",
    "$$\n",
    "\n",
    "Since we have 10 data points, we will get 10 distances from which we then pick the 3 shortest ones. So let's first compute all the 10 distances between `x` and the data points in `D`. Using the built-in methods and the concept of broadcasting, NumPy makes this step very straightforward. In a sense, we can directly implement the formula given above -- particularly notice the first line where we use broadcasting to subtract `x` from all points in `D`; not loop or anything else required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use broadcasting to subtract x from all data points in D\n",
    "R = D - x\n",
    "\n",
    "# Square all elements\n",
    "R = np.square(R)\n",
    "\n",
    "# Sum up all squared elements for each row\n",
    "distances = np.sum(R, axis=1)\n",
    "\n",
    "# Calculate the final square roots\n",
    "distances = np.sqrt(distances)\n",
    "\n",
    "# Print the 10 distances\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04953510",
   "metadata": {},
   "source": [
    "Now that we have all 10 distances, we only need to find the 3 shortest ones. In fact, we want to find the positions/indices of the smallest values in `distances` as they correspond to the 3 most similar data points. Again, NumPy has us covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the 3 most similar data points\n",
    "top_i = np.argsort(distances)[:3]\n",
    "\n",
    "print(top_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db31ca1",
   "metadata": {},
   "source": [
    "Now we know the indices of the data points in `D` are the ones most similar to `x`. Of course, we can also print those 3 data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788df5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D[top_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72443411",
   "metadata": {},
   "source": [
    "**Side note:** Calculating the Euclidean Distances between vectors is such a common task that packages such as `scitkit-learn` provide ready-made methods for it. But note that under the hood, `scitkit-learn` itself relies heavily on NumPy! The code cell below computes the Euclidean Distances between `x` and all data points in `D` using the method [`euclidean-distances()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html) provided by `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "euclidean_distances(D, x.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8000174",
   "metadata": {},
   "source": [
    "### Feature Scaling: Standardization\n",
    "\n",
    "Feature scaling or standardization is an important preprocessing step in data mining and machine learning. It involves transforming the features or variables of a dataset to a common scale or range. Here are the key reasons why feature scaling is important:\n",
    "\n",
    "* **Avoiding bias due to different scales:** Features in a dataset often have different scales and units of measurement. For example, one feature might have values ranging from 0 to 100, while another feature could range from 0 to 1000. These differences in scales can introduce bias in certain machine learning algorithms that are sensitive to the magnitude of features. Scaling the features ensures that they are on a similar scale, preventing certain features from dominating the learning process solely because of their larger values.\n",
    "\n",
    "* **Enhancing convergence and performance:** Many optimization algorithms used in machine learning, such as gradient descent, rely on the assumption that features are on a similar scale. When features have vastly different scales, the convergence of these algorithms can be slow or inefficient. By scaling the features, optimization algorithms can converge more quickly, leading to faster and more accurate models.\n",
    "\n",
    "* **Facilitating distance-based algorithms:** Algorithms that utilize distances or similarities between data points, such as k-nearest neighbors (k-NN) or clustering algorithms, are sensitive to the scale of features. Without proper scaling, features with larger scales can dominate the distance calculations and influence the results disproportionately. Scaling the features ensures that all features contribute fairly to the distance calculations and allows for more reliable and meaningful comparisons.\n",
    "\n",
    "* **Improving model performance and interpretation:** Feature scaling can positively impact the performance of various machine learning models. Models such as support vector machines (SVMs), k-NN, and neural networks often benefit from feature scaling, as it aids in finding optimal hyperplanes, improving decision boundaries, and ensuring efficient model training. Furthermore, feature scaling can make the coefficients or weights in linear models more interpretable and comparable, as they represent the importance or contribution of each feature on a common scale.\n",
    "\n",
    "Common methods of feature scaling include normalization (scaling features to a specific range, e.g., [0, 1]) and standardization (scaling features to have zero mean and unit variance). The choice of scaling method depends on the specific requirements and characteristics of the dataset and the machine learning algorithms being used. Overall, feature scaling or standardization is crucial in data mining as it promotes fairness, efficiency, and effectiveness in various machine learning algorithms, improves model performance, and aids in meaningful interpretation of results.\n",
    "\n",
    "To illustrate the purpose of feature scaling, have second look at the formula for calculating the Euclidean distance -- here for just 2 features:\n",
    "\n",
    "$$\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 }\n",
    "$$\n",
    "\n",
    "As you can see, the Euclidean Distance depends on the difference between the respective feature values. This can cause a problem if the two features are of very different magnitudes. For example, assume that the values of Feature 1 are around 0.0001 while the values of Feature 2 are around 1,000. That means that the values for Feature 1 will hardly affect the Euclidean Distance between to data points since $(p_1 - q_1)^2$ will always be negligible smalled compared to $(p_2 - q_2)^2$.\n",
    "\n",
    "Feature scaling aims to remedy this issue by bringing all features to a common order of magnitude. One approach for feature scaling is **standardization** (scaling features to have zero mean and unit variance). If `x` is a feature and `x_i` is the feature value for data point $i$, each feature value gets standardized by subtracting the feature mean and the feature standard deviation\n",
    "\n",
    "$$\n",
    "x_i = \\frac{x_i - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Let's see how it looks for example. First, we can create another random dataset. In this case, however, we artificially scale up or down the values for the different features. For example, the first feature will be of magnitude 0.01, while the third feature will be of magnitude 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10) # Just to ensure that we get the same random numbers\n",
    "\n",
    "D = np.random.rand(10, 5) * np.array([0.05, 10, 500, 0.1, 50])\n",
    "\n",
    "print('Dataset D:')\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67fedb",
   "metadata": {},
   "source": [
    "Without feature scaling, calculating the Euclidean Distance would most of the time be dominated by Feature 3. This would make Feature 3 more important than the others, which in practice is not a preferred assumption.\n",
    "\n",
    "Using the built-in methods [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) and [`np.std()`](https://numpy.org/doc/stable/reference/generated/numpy.std.html) we can easily calculate the mean and standard deviation for each feature. Note that we need to specify the `axis` parameter for this, otherwise we calculate the mean and standard deviation over all values in `D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mean = np.mean(D, axis=0)\n",
    "col_std = np.std(D, axis=0)\n",
    "\n",
    "print(col_mean, \"<= Means for all features\")\n",
    "print(col_std, \"<= Standard deviations for all features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e5e",
   "metadata": {},
   "source": [
    "With the 5 means and 5 standard deviations for all 5 features, we can again use broadcasting to update each feature value with respect to its \"own\" mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_standardized = (D - col_mean) / col_std\n",
    "\n",
    "print(D_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0b9c6",
   "metadata": {},
   "source": [
    "As you can see, now all features are roughly in the same ballpark, with no features standing out and potentially dominating the calculation of Euclidean Distances.\n",
    "\n",
    "**Side note:** Again, standardization or normalization of the data is a very common task, and as such there are off-the-shelf solutions to accomplish this available. The code below uses the method provided by `scikit-learn`. The results should of course be identical. You can check out the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) class of `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99adc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "D_standardized_sklearn = scaler.fit_transform(D)\n",
    "\n",
    "print(D_standardized_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750bba77-3ef8-4098-96af-f3d2e356d1e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701650f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "NumPy is an indispensable package for data analysis and scientific computing with Python, particularly when working with multidimensional arrays, in the simplest case: vectors and matrices. The appropriate use of the built-in methods not only make your code shorter and easier the read, in the very most cases it will make the actual computations much faster. Having a good understanding and grip on the syntax and inner workings is very beneficial in practice...and definitely in this course :).\n",
    "\n",
    "There's of course much more to NumPy. This tutorial gives only a first glimpse to beginners started. Given its popularity and importance, you can find a lot of documentation online (beyond the official documentation on the NumPy website). To conclude, here are just some more take-away comments.\n",
    "\n",
    "* NumPy is not the perfect solution for all numerical computations. Most basically, NumPy is most suitable for problems and algorithms that can be expressed as vectorized operations. NumPy is also designed that operations run on a single CPU. With the prevalence of GPU computations, new packages such as [CuPy](https://cupy.dev/) have been developed. It allows users to write high-performance GPU-accelerated code using familiar NumPy syntax.\n",
    "\n",
    "* To keep it simple, most of example in this tutorial were only 2d arrays, i.e., matrices where the notion of \"column\" and \"row\" are meaningful and intuitive. For arrays with more dimensions these notions break down. In general, it's a good practice to always thing in \"first dimension/axis\", \"second dimensions/axis\", \"third dimensions/axis\", etc. Trying to talk about rows and columns in case of multidimensional arrays quickly becomes more confusing than helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6ffb9-47b4-4851-8225-5edbe01cff43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ba504",
   "metadata": {},
   "source": [
    "## Optional \"Homework\"\n",
    "\n",
    "In the first example use case, we calculated the Euclidean Distances between a single data point `x` and all data points in `D`. This allowed us to use broadcasting to subtract data point `x` from all points in `D`.\n",
    "\n",
    "Now let's assume we have, say, 5 data points `x1`, `x2`, ..., `x5`, and we want to find the k-nearest neighbors for all 5 data points. This requires calculating 50 Euclidean distances, 10 for each `x_i`. Of course, we could simply loop over all `x_i` and perform the steps for each data point as outlined above. However, using loops can significantly affect the runtime for large datasets (not for this small example).\n",
    "\n",
    "**Question:** How can we use NumPy to calculate all Euclidean Distances without using any loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310]",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
